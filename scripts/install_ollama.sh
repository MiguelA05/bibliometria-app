#!/bin/bash
# Script de instalaciÃ³n de Ollama y modelo para BibliometrÃ­a App

set -e

echo "=========================================="
echo "InstalaciÃ³n de Ollama para BibliometrÃ­a App"
echo "=========================================="
echo ""

# Verificar si Ollama ya estÃ¡ instalado
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama ya estÃ¡ instalado"
    ollama --version
else
    echo "ðŸ“¥ Instalando Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh
    echo "âœ… Ollama instalado correctamente"
fi

echo ""
echo "=========================================="
echo "Iniciando servidor Ollama..."
echo "=========================================="

# Iniciar servidor Ollama en background si no estÃ¡ corriendo
if ! pgrep -x "ollama" > /dev/null; then
    echo "ðŸš€ Iniciando servidor Ollama..."
    ollama serve &
    sleep 3
    echo "âœ… Servidor Ollama iniciado"
else
    echo "âœ… Servidor Ollama ya estÃ¡ corriendo"
fi

echo ""
echo "=========================================="
echo "Descargando modelos..."
echo "=========================================="

# Descargar Llama 3.2 3B (mÃ¡s ligero y rÃ¡pido)
echo "ðŸ“¥ Descargando Llama 3.2 3B (esto puede tardar varios minutos)..."
ollama pull llama3.2:3b

# Opcional: Descargar Mistral 7B (mÃ¡s pesado pero mejor calidad)
read -p "Â¿Deseas tambiÃ©n descargar Mistral 7B? (s/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Ss]$ ]]; then
    echo "ðŸ“¥ Descargando Mistral 7B (esto puede tardar varios minutos)..."
    ollama pull mistral:7b
fi

echo ""
echo "=========================================="
echo "Verificando instalaciÃ³n..."
echo "=========================================="

# Verificar que los modelos estÃ¡n disponibles
echo "ðŸ“‹ Modelos disponibles:"
ollama list

echo ""
echo "âœ… InstalaciÃ³n completada!"
echo ""
echo "Para usar el modelo en el cÃ³digo, usa:"
echo "  - llama3.2:3b (recomendado para velocidad)"
echo "  - mistral:7b (recomendado para calidad)"

