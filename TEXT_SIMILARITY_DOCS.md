# ğŸ”¬ Sistema de AnÃ¡lisis de Similitud Textual

## ğŸ“‹ Objetivo

ImplementaciÃ³n de **6 algoritmos de similitud textual** (4 clÃ¡sicos + 2 basados en IA) para analizar la similitud entre abstracts de artÃ­culos acadÃ©micos extraÃ­dos de CSV unificados.

---

## ğŸ¯ Algoritmos Implementados

### **ClÃ¡sicos (4 algoritmos):**

#### 1. **Levenshtein (Distancia de EdiciÃ³n)**
- **Tipo:** Caracteres
- **Complejidad:** O(nÂ²)
- **Output:**
  - Distancia (nÃºmero de operaciones)
  - Matriz DP (opcional)
  - Backtrace (transformaciones)

#### 2. **Damerau-Levenshtein**
- **Tipo:** Caracteres con transposiciÃ³n
- **Diferencia:** Permite intercambiar caracteres adyacentes como 1 operaciÃ³n
- **Output:**
  - Distancia
  - Transposiciones detectadas
  - Ejemplos de transposiciones

#### 3. **Jaccard sobre Shingles (n-grams)**
- **Tipo:** Tokens/conjuntos
- **Configurable:** longitud de n-grams (n=1,2,3...)
- **Output:**
  - Score de Jaccard
  - Shingles comunes
  - Lista de n-grams compartidos

#### 4. **TF-IDF Cosine Similarity**
- **Tipo:** VectorizaciÃ³n estadÃ­stica
- **CaracterÃ­sticas:**
  - TF-IDF para pesos
  - Cosine similarity para comparaciÃ³n
  - n-grams (1-3)
- **Output:**
  - Score de similitud
  - Top tÃ©rminos que contribuyen
  - TF-IDF de cada tÃ©rmino

### **IA (2 algoritmos):**

#### 5. **Sentence-BERT (Embeddings SemÃ¡nticos)**
- **Modelo:** paraphrase-MiniLM-L6-v2
- **Dimensiones:** 384
- **Tipo:** Similitud semÃ¡ntica (no lÃ©xica)
- **Output:**
  - Coseno de similitud semÃ¡ntica
  - InterpretaciÃ³n del score
  - AnÃ¡lisis conceptual

#### 6. **LLM-based Similarity (Simulado)**
- **Tipo:** SimulaciÃ³n de razonamiento LLM
- **CaracterÃ­sticas:**
  - AnÃ¡lisis de temas comunes
  - Overlap semÃ¡ntico
  - JustificaciÃ³n textual
- **Nota:** Listo para integrar con API real (OpenAI, GPT, etc.)

---

## ğŸ”§ Preprocesamiento de Texto

### **Pipelines segÃºn Algoritmo:**

#### **Char-level** (Levenshtein, Damerau):
```python
1. NormalizaciÃ³n Unicode (NFKC)
2. MinÃºsculas
3. Limpiar espacios
```

#### **Token-level** (Jaccard):
```python
1. NormalizaciÃ³n Unicode
2. MinÃºsculas
3. TokenizaciÃ³n
4. Remover puntuaciÃ³n
```

#### **Standard** (TF-IDF, Sentence-BERT):
```python
1. NormalizaciÃ³n Unicode
2. MinÃºsculas
3. TokenizaciÃ³n
4. Remover stopwords
5. Stemming (Porter)
```

### **Pasos de NormalizaciÃ³n:**

1. **Unicode NFKC:** Normaliza caracteres especiales
2. **Lowercase:** EstandarizaciÃ³n
3. **TokenizaciÃ³n:** Por algoritmo
4. **Stopwords Removal:** Elimina palabras comunes
5. **Stemming:** Reduce palabras a raÃ­z
6. **n-grams:** Genera shingles

---

## ğŸ“Š Estructura de Salida

### **Formato SimilarityResult:**
```python
{
    "algorithm_name": "Levenshtein (Edit Distance)",
    "similarity_score": 0.856,
    "explanation": "...detallada...",
    "details": {
        "distance": 45,
        "max_length": 320,
        "matrix": [...],
        "backtrace": [...]
    },
    "processing_time": 0.023
}
```

### **Ejemplo de ExplicaciÃ³n:**
```
Levenshtein Distance: 45 operaciones
- Insertions: 10 caracteres a agregar
- Deletions: 20 caracteres a eliminar
- Substitutions: 15 caracteres a reemplazar
- Distance/Max_length ratio: 45/320 = 0.141
Similarity = 1 - ratio = 0.859
```

---

## ğŸš€ API Endpoints

### 1. **Analizar Similitud**
```
POST /api/v1/text-similarity/analyze

Request:
{
    "csv_file_path": "results/unified/unified_xxx.csv",
    "article_indices": [0, 1, 2]
}

Response:
{
    "articles": [...],
    "results": [
        {
            "algorithm": "...",
            "score": 0.85,
            "explanation": "...",
            "details": {...}
        }
    ]
}
```

### 2. **Listar CSVs Disponibles**
```
GET /api/v1/text-similarity/csv-list

Response:
{
    "csvs": [
        {
            "filename": "unified_xxx.csv",
            "filepath": "...",
            "size_kb": 42.3
        }
    ],
    "total": 1
}
```

---

## ğŸ’» Uso del Sistema

### **1. Preparar Datos:**
```bash
# Generar CSV unificado
python test_system.py
```

### **2. Analizar Similitud:**
```bash
# Probar con artÃ­culos especÃ­ficos
python test_text_similarity.py
```

### **3. Instalar Dependencias:**
```bash
pip install scikit-learn nltk sentence-transformers
python -m nltk.downloader punkt stopwords
```

---

## ğŸ“ Archivos del Sistema

```
app/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ text_similarity_service.py    # 6 algoritmos implementados
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ text_extractor.py             # Lectura de CSVs
â”œâ”€â”€ api/
â”‚   â””â”€â”€ text_similarity_endpoints.py  # Endpoints API
â””â”€â”€ main.py                           # IntegraciÃ³n

tests/
â””â”€â”€ test_text_similarity.py           # Script de prueba
```

---

## ğŸ¯ CaracterÃ­sticas Clave

âœ… **6 algoritmos:** 4 clÃ¡sicos + 2 IA  
âœ… **Preprocesamiento adaptativo:** segÃºn algoritmo  
âœ… **Output detallado:** explicaciones paso a paso  
âœ… **MatemÃ¡tica visible:** matrices, operaciones, transformaciones  
âœ… **Integrado:** lee CSV unificados automÃ¡ticamente  
âœ… **Extensible:** fÃ¡cil agregar mÃ¡s algoritmos  

---

## ğŸ“Š Ejemplo de Resultado Completo

```json
{
  "articles_analyzed": [
    {"index": 0, "title": "Machine Learning in AI"},
    {"index": 1, "title": "Deep Learning Applications"}
  ],
  "similarity_results": [
    {
      "algorithm": "Levenshtein",
      "score": 0.856,
      "explanation": "...",
      "details": {
        "distance": 45,
        "operations": ["insert", "substitute"]
      }
    },
    {
      "algorithm": "Sentence-BERT",
      "score": 0.912,
      "explanation": "...",
      "interpretation": "Very similar (likely same topic)"
    }
  ],
  "summary": {
    "avg_similarity": 0.884,
    "algorithms_used": 6
  }
}
```

---

## ğŸ”¬ MatemÃ¡tica Detallada

Ver documentaciÃ³n especÃ­fica en cÃ³digo:
- LÃ­neas 121-166: `calculate_similarity_score()` - Levenshtein
- LÃ­neas 168-182: `_calculate_text_similarity()` - Jaccard
- LÃ­neas 423-493: `tfidf_cosine_similarity()` - TF-IDF
- Sentence-BERT: utiliza modelo pre-entrenado

---

Â¡Sistema completo y listo para usar!
