# üî¨ OPENALEX SERVICE - L√≥gica de Implementaci√≥n

## üìã Objetivo

El `OpenAlexService` es el servicio principal que interact√∫a con la API de OpenAlex para descargar, procesar y exportar datos de art√≠culos acad√©micos, incluyendo informaci√≥n geogr√°fica integrada.

---

## üèóÔ∏è Arquitectura del Servicio

### Clase Principal

```python
class OpenAlexService:
    """
    Servicio para interactuar con la API de OpenAlex.
    Reemplaza completamente el web scraping con llamadas a la API REST.
    """
```

**Responsabilidades:**
- Hacer peticiones a la API de OpenAlex
- Procesar metadatos de art√≠culos acad√©micos
- Extraer informaci√≥n completa (t√≠tulo, autores, instituciones, etc.)
- Integrar datos geogr√°ficos
- Exportar resultados a CSV organizados

---

## üîÑ Flujo Principal: search_works()

**Ubicaci√≥n:** L√≠neas 38-122

### Proceso Completo

```
1. BUSCAR EN OPENALEX
   POST /api/works?search=query&per_page=30
   ‚Üì
2. PROCESAR CADA WORK
   for work in works:
       article = _process_work(work)
       ‚Üì
3. EXPORTAR A CSV
   CSV guardado en results/raw_data/
   ‚Üì
4. RETORNAR RESULTADOS
   (articles, csv_file_path)
```

**C√≥digo Clave:**
```python
def search_works(self, query, max_articles, filters):
    # L√≠nea 60-63: Construir par√°metros
    params = {
        'search': query,
        'per_page': max_articles
    }
    
    # L√≠nea 76: Hacer petici√≥n a API
    response = self.session.get(
        f"{self.base_url}/works",
        params=params,
        timeout=settings.openalex_timeout
    )
    
    # L√≠nea 80: Obtener results
    works = response.json().get('results', [])
    
    # L√≠nea 90-98: Procesar cada work
    for work in works:
        article = self._process_work(work)
        articles.append(article)
    
    # L√≠nea 116: Exportar a CSV
    csv_file_path = self._export_to_csv(articles, query)
    
    return articles, csv_file_path
```

---

## üß© Componentes Clave

### 1. Procesamiento de un Work (_process_work)

**Ubicaci√≥n:** L√≠neas 124-233

**L√≥gica Secuencial:**

```python
def _process_work(work):
    # Paso 1: Extraer t√≠tulo
    title = work.get('title')  # L√≠nea 136
    
    # Paso 2: Extraer autores y afiliaciones
    authors, affiliations = _extract_authors_and_affiliations(work)  # L√≠nea 145
    
    # Paso 3: Extraer fechas
    publication_date = _extract_publication_date(work)  # L√≠nea 148
    publication_year = work.get('publication_year')  # L√≠nea 149
    
    # Paso 4: Extraer URLs
    article_url = _extract_article_url(work)  # L√≠nea 154
    doi = work.get('doi')  # L√≠nea 155
    
    # Paso 5: Extraer informaci√≥n de la fuente
    source_info = _extract_source_info(work)  # L√≠nea 169
    
    # Paso 6: Extraer informaci√≥n Open Access
    oa_info = _extract_open_access_info(work)  # L√≠nea 172
    
    # Paso 7: Extraer conceptos/temas
    concepts, topics = _extract_concepts_and_topics(work)  # L√≠nea 175
    
    # Paso 8: Extraer datos geogr√°ficos (üÜï)
    geographic_data = self.geographic_service.extract_geographic_data(work)  # L√≠nea 184
    
    # Paso 9: Crear objeto ArticleMetadata
    article = ArticleMetadata(
        title=title,
        authors=authors,
        affiliations=affiliations,
        # ... todos los campos
        # + datos geogr√°ficos
        institution_countries=geographic_data.get('institution_countries'),
        geographic_coordinates=geographic_data.get('geographic_coordinates')
    )
    
    return article
```

---

### 2. Extracci√≥n de Autores y Afiliaciones

**Funci√≥n:** `_extract_authors_and_affiliations()` (l√≠neas 265-325)

**L√≥gica:**
```python
def _extract_authors_and_affiliations(work):
    authors = []
    affiliations = []
    
    # Iterar sobre authorships
    for authorship in work.get('authorships', []):
        # Extraer nombre del autor
        author = authorship.get('author', {})
        authors.append(author.get('display_name'))
        
        # Extraer informaci√≥n de instituciones con datos geogr√°ficos
        for institution in authorship.get('institutions', []):
            parts = [institution.get('display_name')]
            
            # Agregar ciudad, regi√≥n, pa√≠s
            if institution.get('city'):
                parts.append(institution.get('city'))
            if institution.get('country_code'):
                parts.append(institution.get('country_code'))
            
            affiliations.append(", ".join(parts))
    
    return authors, affiliations
```

**Resultado:**
```python
authors = ['John Smith', 'Jane Doe']
affiliations = [
    'MIT, Cambridge, US',
    'Harvard University, Boston, US'
]
```

---

### 3. Extracci√≥n de Fecha de Publicaci√≥n

**Funci√≥n:** `_extract_publication_date()` (l√≠neas 327-353)

**Estrategia Cascada:**
```python
def _extract_publication_date(work):
    # Prioridad 1: Fecha completa
    if work.get('publication_date'):
        return work['publication_date']  # "2023-07-13"
    
    # Prioridad 2: Construir desde componentes
    year = work.get('publication_year')   # 2023
    month = work.get('publication_month') # 7
    day = work.get('publication_day')    # 13
    
    if year:
        date_parts = [str(year)]
        if month:
            date_parts.append(f"{int(month):02d}")  # "07"
            if day:
                date_parts.append(f"{int(day):02d}")  # "13"
        return '-'.join(date_parts)  # "2023-07-13"
    
    # Prioridad 3: Usar fecha de creaci√≥n del registro
    if work.get('created_date'):
        return work['created_date'].split('T')[0]
    
    # Fallback
    return "Date not available"
```

---

### 4. Extracci√≥n de URL del Art√≠culo

**Funci√≥n:** `_extract_article_url()` (l√≠neas 355-374)

**Prioridades:**
```python
def _extract_article_url(work):
    # 1. URL de Open Access (preferida)
    oa_url = work.get('open_access', {}).get('oa_url')
    if oa_url:
        return oa_url
    
    # 2. URL primaria del art√≠culo
    landing_page = work.get('primary_location', {}).get('landing_page_url')
    if landing_page:
        return landing_page
    
    # 3. URL de OpenAlex
    if work.get('id'):
        return work.get('id')
    
    # 4. Fallback
    return "URL not available"
```

---

### 5. Exportaci√≥n a CSV

**Funci√≥n:** `_export_to_csv()` (l√≠neas 423-493)

**Ubicaci√≥n de Archivo:**
```python
base_dir = settings.results_dir           # "results"
raw_data_dir = os.path.join(base_dir, "raw_data")  # "results/raw_data"

filename = f"resultados_openalex_{query}_{timestamp}.csv"
file_path = os.path.join(raw_data_dir, filename)
```

**Estructura de Datos Exportada:**
```python
for article in articles:
    article_dict = {
        # Campos b√°sicos
        'title': article.title,
        'authors': '; '.join(article.authors),
        'abstract': article.abstract,
        
        # Campos de OpenAlex
        'doi': article.doi,
        'cited_by_count': article.cited_by_count,
        
        # Campos geogr√°ficos (üÜï)
        'institution_countries': '; '.join(article.institution_countries),
        'institution_cities': '; '.join(article.institution_cities),
        'geographic_coordinates': json.dumps(article.geographic_coordinates),
        
        # ... todos los dem√°s campos
    }
```

**Encoding:**
```python
# Configurado en settings
encoding = settings.csv_encoding  # 'utf-8'
```

---

## üåç Integraci√≥n con Geographic Service

### L√≠nea 14: Import
```python
from app.services.geographic_service import GeographicDataService
```

### L√≠nea 36: Inicializaci√≥n
```python
def __init__(self):
    # ...
    self.geographic_service = GeographicDataService()
```

### L√≠nea 184: Uso
```python
geographic_data = self.geographic_service.extract_geographic_data(work)
```

### L√≠neas 222-226: Integraci√≥n en ArticleMetadata
```python
article = ArticleMetadata(
    # ... otros campos
    author_countries=geographic_data.get('author_countries'),
    author_cities=geographic_data.get('author_cities'),
    institution_countries=geographic_data.get('institution_countries'),
    institution_cities=geographic_data.get('institution_cities'),
    geographic_coordinates=geographic_data.get('geographic_coordinates')
)
```

### L√≠neas 476-480: Exportaci√≥n Geogr√°fica
```python
article_dict = {
    # ... otros campos
    'author_countries': '; '.join(article.author_countries) if article.author_countries else '',
    'author_cities': '; '.join(article.author_cities) if article.author_cities else '',
    'institution_countries': '; '.join(article.institution_countries) if article.institution_countries else '',
    'institution_cities': '; '.join(article.institution_cities) if article.institution_cities else '',
    'geographic_coordinates': json.dumps(article.geographic_coordinates) if article.geographic_coordinates else ''
}
```

---

## üîß Funciones Auxiliares

### 1. Extracci√≥n de Abstract

**Funci√≥n:** `_extract_abstract()` (l√≠neas 235-263)

**Estrategia Multi-fuente:**
```python
def _extract_abstract(work):
    # Prioridad 1: Abstract directo
    if work.get('abstract'):
        return work['abstract']
    
    # Prioridad 2: Reconstruir desde √≠ndice invertido
    if work.get('abstract_inverted_index'):
        # Algoritmo de reconstrucci√≥n
        words = []
        for word, positions in work['abstract_inverted_index'].items():
            for pos in positions:
                words.append((pos, word))
        words.sort()
        return ' '.join([word for _, word in words])
    
    # Prioridad 3: Campos alternativos
    for field in ['summary', 'description', 'content']:
        if work.get(field):
            return work[field]
    
    # Fallback
    return "Abstract not available"
```

---

### 2. Extracci√≥n de Conceptos y Topics

**Funci√≥n:** `_extract_concepts_and_topics()` (l√≠neas 403-412)

```python
def _extract_concepts_and_topics(work):
    concepts = work.get('concepts', [])
    topics = []
    
    for concept in concepts:
        if concept.get('display_name'):
            topics.append(concept.get('display_name'))
    
    return concepts, topics
```

**Ejemplo:**
```python
# Input OpenAlex
concepts = [
    {'display_name': 'Machine Learning', 'score': 0.9},
    {'display_name': 'Artificial Intelligence', 'score': 0.8}
]

# Output
topics = ['Machine Learning', 'Artificial Intelligence']
```

---

### 3. Extracci√≥n de Open Access Info

**Funci√≥n:** `_extract_open_access_info()` (l√≠neas 393-401)

```python
def _extract_open_access_info(work):
    open_access = work.get('open_access', {})
    
    return {
        'is_oa': open_access.get('is_oa'),          # True/False
        'oa_url': open_access.get('oa_url'),         # URL del PDF
        'oa_status': open_access.get('oa_status')    # 'gold', 'green', etc.
    }
```

---

## üìä Estructura de Datos OpenAlex

### Campos Mapeados

```
OpenAlex Work ‚Üí ArticleMetadata
‚îú‚îÄ‚îÄ title ‚Üí title
‚îú‚îÄ‚îÄ abstract ‚Üí abstract
‚îú‚îÄ‚îÄ authorships ‚Üí authors + affiliations
‚îÇ   ‚îú‚îÄ‚îÄ author.display_name ‚Üí authors[]
‚îÇ   ‚îî‚îÄ‚îÄ institutions[].display_name ‚Üí affiliations[]
‚îú‚îÄ‚îÄ publication_year ‚Üí publication_year
‚îú‚îÄ‚îÄ publication_date ‚Üí publication_date
‚îú‚îÄ‚îÄ doi ‚Üí doi
‚îú‚îÄ‚îÄ openalex_id ‚Üí openalex_id
‚îú‚îÄ‚îÄ open_access ‚Üí is_oa, oa_url, oa_status
‚îú‚îÄ‚îÄ primary_location ‚Üí article_url
‚îú‚îÄ‚îÄ concepts ‚Üí topics[]
‚îú‚îÄ‚îÄ cited_by_count ‚Üí cited_by_count
‚îî‚îÄ‚îÄ authorships ‚Üí geographic_data (üÜï)
    ‚îî‚îÄ‚îÄ institutions[] ‚Üí institution_countries, geographic_coordinates
```

---

## üéØ Casos de Uso

### Caso 1: Art√≠culo Completo

**Input OpenAlex:**
```json
{
    "title": "Machine Learning Applications",
    "doi": "10.1234/ml",
    "authorships": [{
        "author": {"display_name": "John Smith"},
        "institutions": [{
            "display_name": "MIT",
            "country_code": "US",
            "city": "Cambridge"
        }]
    }],
    "cited_by_count": 100
}
```

**Output ArticleMetadata:**
```python
ArticleMetadata(
    title="Machine Learning Applications",
    doi="10.1234/ml",
    authors=["John Smith"],
    affiliations=["MIT, Cambridge, US"],
    cited_by_count=100,
    institution_countries=["United States"],
    institution_cities=["Cambridge"],
    geographic_coordinates=[...]
)
```

---

### Caso 2: Manejo de Errores

```python
def _process_work(work):
    try:
        # Procesar...
        return article
    except Exception as e:
        print(f"‚ö†Ô∏è Error procesando trabajo: {e}")
        return None  # Retorna None si hay error (se omite)
```

**Estrategia:** Fail gracefully - omite art√≠culos con error

---

## üîê Configuraci√≥n y Seguridad

### Headers HTTP

**L√≠nea 29-32:**
```python
self.headers = {
    'User-Agent': f'{settings.openalex_user_agent} (mailto:{email})'
}
self.session.headers.update(self.headers)
```

**Polite Pool:**
- Incluir email en User-Agent da acceso a "polite pool"
- L√≠mites m√°s generosos
- Prioridad en peticiones

---

## üìÅ Organizaci√≥n de Archivos Exportados

**Ruta:**
```python
results/
‚îî‚îÄ‚îÄ raw_data/
    ‚îî‚îÄ‚îÄ resultados_openalex_{query}_{timestamp}.csv
```

**Formato de Nombre:**
```python
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
safe_query = re.sub(r'[^\w\s-]', '', search_query).strip()
filename = f"resultados_openalex_{safe_query}_{timestamp}.csv"
```

**Ejemplo:**
```
resultados_openalex_generative_artificial_intelligence_20251027_123045.csv
```

---

## ‚úÖ Ventajas de Esta Implementaci√≥n

1. **API REST:** No depende de web scraping
2. **Manejo de Errores:** Fail gracefully
3. **Logging:** Trazabilidad completa
4. **Performance:** Timeout configurable
5. **Flexibilidad:** Filtros y par√°metros configurables
6. **Geograf√≠a Integrada:** Datos geogr√°ficos autom√°ticos
7. **Organizaci√≥n:** CSV en carpetas espec√≠ficas

---

## üéØ Resumen

**File:** `app/services/openalex_service.py`  
**L√≠neas:** 513 l√≠neas  
**Clase principal:** `OpenAlexService`  
**Funci√≥n principal:** `search_works()`  
**Dependencia:** `GeographicDataService` (l√≠nea 14)  
**Exportaci√≥n:** CSV en `results/raw_data/`  
**Encoding:** UTF-8 configurado en settings  
**Geograf√≠a:** Integrada autom√°ticamente (l√≠neas 184, 222-226)
