# üî¨ Sistema de An√°lisis de Similitud Textual - Gu√≠a de Uso

## ‚úÖ Integraci√≥n Completada

Los endpoints de similitud textual est√°n integrados en `app/api/endpoints.py` y funcionan junto con los dem√°s endpoints del sistema.

---

## üéØ Endpoints Disponibles

### 1. **Analizar Similitud Textual**
```
POST /api/v1/text-similarity/analyze
```

**Request Body:**
```json
{
    "csv_file_path": "results/unified/unified_xxx.csv",
    "article_indices": [0, 1, 2]
}
```

**Response:**
```json
{
    "articles": [
        {"index": 0, "title": "Article 1"},
        {"index": 1, "title": "Article 2"}
    ],
    "results": [
        {
            "algorithm": "Levenshtein (Edit Distance)",
            "score": 0.856,
            "explanation": "...",
            "details": {...},
            "time": 0.023
        },
        ...
    ],
    "summary": {
        "algorithms_used": 6,
        "avg_similarity": 0.782
    }
}
```

### 2. **Listar CSVs Disponibles**
```
GET /api/v1/text-similarity/csv-list
```

**Response:**
```json
{
    "csvs": [
        {
            "filename": "unified_xxx.csv",
            "filepath": "results/unified/unified_xxx.csv",
            "size_kb": 42.3,
            "modified": 1234567890
        }
    ],
    "total": 1
}
```

---

## üî¨ Algoritmos Implementados

### **Cl√°sicos:**

1. **Levenshtein** - Distancia de edici√≥n
2. **Damerau-Levenshtein** - Con transposici√≥n
3. **Jaccard** - Sobre shingles (n-grams)
4. **TF-IDF Cosine** - Vectorizaci√≥n estad√≠stica

### **IA:**

5. **Sentence-BERT** - Embeddings sem√°nticos
6. **LLM-based** - Similarity simulado

---

## üìù Uso R√°pido

### **Ejemplo con Python:**
```python
import requests

# Analizar similitud
response = requests.post(
    "http://127.0.0.1:8000/api/v1/text-similarity/analyze",
    json={
        "csv_file_path": "results/unified/unified_xxx.csv",
        "article_indices": [0, 1, 2]
    }
)

results = response.json()
print(results['summary'])
```

### **Ejemplo con Script:**
```bash
python test_text_similarity.py
```

---

## üîß Instalaci√≥n de Dependencias

```bash
# Instalar librer√≠as necesarias
pip install scikit-learn nltk sentence-transformers

# Descargar datos de NLTK
python -m nltk.downloader punkt stopwords
```

---

## üìä Todos los Endpoints del Sistema

```
GET  /                              - Ra√≠z de la API
GET  /health                        - Estado del sistema
GET  /metrics                       - M√©tricas de rendimiento

POST /api/v1/fetch-metadata         - Extraer metadatos de OpenAlex
POST /api/v1/uniquindio/generative-ai  - Endpoint universitario
POST /api/v1/automation/unified-data    - Automatizaci√≥n completa

POST /api/v1/text-similarity/analyze   - Analizar similitud textual ‚ú®
GET  /api/v1/text-similarity/csv-list   - Listar CSVs disponibles ‚ú®
```

---

## ‚úÖ Integraci√≥n Completa

**Archivos clave:**
- `app/api/endpoints.py` - Todos los endpoints en un solo archivo
- `app/services/text_similarity_service.py` - L√≥gica de los algoritmos
- `app/utils/text_extractor.py` - Lectura de CSVs
- `app/main.py` - Aplicaci√≥n principal

**¬°Todo listo para usar!** üéâ
