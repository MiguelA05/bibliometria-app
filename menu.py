#!/usr/bin/env python3
"""
Punto de entrada principal para Bibliometr√≠a App
Combina el men√∫ interactivo y el servidor FastAPI en una sola aplicaci√≥n.
"""

import os
import sys
import subprocess
import threading
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import pandas as pd

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent))

from app.services.data_unification_service import DataUnificationService
from app.services.text_similarity_service import TextSimilarityService
from app.services.word_frequency_service import WordFrequencyService
from app.services.hierarchical_clustering_service import HierarchicalClusteringService
from app.services.visualization_service import VisualizationService
from app.utils.text_extractor import TextExtractor, get_unified_csv_list
from app.config import settings

# Intentar importar helpers del servidor
try:
    from app.utils.server_helper import (
        check_server_running,
        start_server,
        ensure_server_ready,
        get_server_status
    )
    SERVER_HELPER_AVAILABLE = True
except ImportError:
    SERVER_HELPER_AVAILABLE = False
    check_server_running = None
    start_server = None
    ensure_server_ready = None
    get_server_status = None


class MenuPrincipal:
    """Men√∫ principal interactivo."""
    
    def __init__(self):
        self.unification_service = DataUnificationService()
        self.similarity_service = TextSimilarityService()
        self.word_frequency_service = WordFrequencyService()
        self.clustering_service = HierarchicalClusteringService()
        self.visualization_service = VisualizationService()
        self.text_extractor = TextExtractor()
        
        # Iniciar servidor FastAPI autom√°ticamente
        self._iniciar_servidor_automatico()
    
    def _iniciar_servidor_automatico(self):
        """Iniciar el servidor FastAPI autom√°ticamente al iniciar el men√∫."""
        if not SERVER_HELPER_AVAILABLE:
            print("\n[WARNING] Helper del servidor no disponible")
            print("[INFO] El servidor FastAPI no se iniciar√° autom√°ticamente")
            return
        
        print("\n" + "="*70)
        print("INICIANDO SERVIDOR FASTAPI")
        print("="*70)
        
        if check_server_running():
            status = get_server_status() if get_server_status else None
            if status:
                print(f"[OK] Servidor FastAPI ya est√° corriendo en {status.get('url', 'N/A')}")
            else:
                print("[OK] Servidor FastAPI ya est√° corriendo")
        else:
            print(f"[INFO] Iniciando servidor FastAPI en http://{settings.api_host}:{settings.api_port}...")
            if ensure_server_ready():
                status = get_server_status() if get_server_status else None
                if status:
                    print(f"[OK] Servidor FastAPI iniciado exitosamente")
                    print(f"[INFO] URL: {status.get('url', 'N/A')}")
                    print(f"[INFO] Documentaci√≥n: {status.get('url', 'N/A')}/docs")
                else:
                    print("[OK] Servidor FastAPI iniciado exitosamente")
            else:
                print("[WARNING] No se pudo iniciar el servidor FastAPI autom√°ticamente")
                print("[INFO] Puedes iniciarlo manualmente con: python start.py")
        
        print("="*70)
        time.sleep(1)  # Pausa breve para que el usuario vea el mensaje
        
    def limpiar_pantalla(self):
        """Limpiar la pantalla."""
        os.system('clear' if os.name != 'nt' else 'cls')
    
    def mostrar_banner(self):
        """Mostrar banner del men√∫."""
        print("\n" + "="*70)
        print(" " * 15 + "BIBLIOMETR√çA APP - PUNTO DE ENTRADA UNIFICADO")
        print("="*70)
        print("\nRequerimiento 1: Automatizaci√≥n de descarga y unificaci√≥n de datos")
        print("Requerimiento 2: An√°lisis de similitud textual con 6 algoritmos")
        print("Requerimiento 3: An√°lisis de frecuencia de palabras")
        print("Requerimiento 4: Agrupamiento jer√°rquico de abstracts")
        print("Requerimiento 5: An√°lisis visual (mapas, nubes, l√≠neas temporales)")
        print("API REST: Servidor FastAPI con endpoints para todos los servicios")
        print("="*70 + "\n")
    
    def mostrar_menu_principal(self):
        """Mostrar men√∫ principal."""
        print("\n[MEN√ö PRINCIPAL]")
        print("-" * 70)
        print("1. Probar Web Scraping y Generar Resultados (Requerimiento 1)")
        print("2. Evaluar Algoritmos de Similitud Textual (Requerimiento 2)")
        print("3. An√°lisis de Frecuencia de Palabras (Requerimiento 3)")
        print("4. Agrupamiento Jer√°rquico de Abstracts (Requerimiento 4)")
        print("5. An√°lisis Visual (Requerimiento 5)")
        print("6. Salir")
        print("-" * 70)
    
    def mostrar_submenu_scraping(self):
        """Mostrar submen√∫ de scraping."""
        print("\n[WEB SCRAPING Y GENERACI√ìN DE RESULTADOS]")
        print("-" * 70)
        print("1. Ejecutar proceso completo de automatizaci√≥n")
        print("2. Ver resultados generados")
        print("3. Volver al men√∫ principal")
        print("-" * 70)
    
    def mostrar_submenu_similitud(self):
        """Mostrar submen√∫ de similitud."""
        print("\n[AN√ÅLISIS DE SIMILITUD TEXTUAL]")
        print("-" * 70)
        print("1. Seleccionar archivo CSV unificado")
        print("2. Seleccionar art√≠culos y analizar")
        print("3. Ver algoritmos disponibles")
        print("4. Volver al men√∫ principal")
        print("-" * 70)
    
    def ejecutar_proceso_automatizacion(self):
        """Ejecutar el proceso completo de automatizaci√≥n."""
        print("\n" + "="*70)
        print("PROCESO DE AUTOMATIZACI√ìN - REQUERIMIENTO 1")
        print("="*70)
        
        # Solicitar par√°metros
        print("\nPar√°metros de configuraci√≥n:")
        query = input("Consulta de b√∫squeda [generative artificial intelligence]: ").strip()
        if not query:
            query = "generative artificial intelligence"
        
        try:
            max_articles = input("Art√≠culos por fuente [350]: ").strip()
            max_articles = int(max_articles) if max_articles else 350
        except ValueError:
            max_articles = 350
        
        try:
            threshold = input("Umbral de similitud para duplicados [0.75]: ").strip()
            threshold = float(threshold) if threshold else 0.75
        except ValueError:
            threshold = 0.75
        
        print(f"\n[INFO] Iniciando proceso de automatizaci√≥n...")
        print(f"  - Consulta: {query}")
        print(f"  - Art√≠culos por fuente: {max_articles}")
        print(f"  - Umbral de similitud: {threshold}")
        print(f"  - Fuentes: OpenAlex, PubMed, ArXiv")
        print("\n[INFO] Esto puede tardar varios minutos...")
        
        # Ejecutar proceso
        resultado = self.unification_service.run_automated_process(
            base_query=query,
            similarity_threshold=threshold,
            max_articles_per_source=max_articles
        )
        
        if resultado['success']:
            print("\n" + "="*70)
            print("PROCESO COMPLETADO EXITOSAMENTE")
            print("="*70)
            print(f"\nEstad√≠sticas:")
            print(f"  - Total descargados: {resultado['total_articles_downloaded']}")
            print(f"  - Art√≠culos √∫nicos: {resultado['unique_articles']}")
            print(f"  - Duplicados eliminados: {resultado['duplicates_removed']}")
            print(f"  - Tiempo de procesamiento: {resultado['processing_time_seconds']:.2f} segundos")
            
            print(f"\nArchivos generados:")
            print(f"  - Archivo unificado: {resultado['unified_file']}")
            print(f"  - Archivo de duplicados: {resultado['duplicates_file']}")
            
            # Verificar estructura de directorios
            print(f"\nEstructura de archivos:")
            self.mostrar_estructura_resultados()
        else:
            print(f"\n[ERROR] Error en el proceso: {resultado.get('error', 'Error desconocido')}")
        
        input("\nPresiona Enter para continuar...")
    
    def mostrar_estructura_resultados(self):
        """Mostrar estructura de directorios de resultados."""
        base_dir = Path(settings.results_dir)
        
        print(f"\n  {base_dir}/")
        
        # Raw data
        raw_dir = base_dir / "raw_data"
        if raw_dir.exists():
            csv_files = list(raw_dir.glob("*.csv"))
            print(f"  ‚îú‚îÄ‚îÄ raw_data/ ({len(csv_files)} archivos)")
            for csv in csv_files[-3:]:  # Mostrar √∫ltimos 3
                print(f"  ‚îÇ   ‚îî‚îÄ‚îÄ {csv.name}")
        
        # Unified
        unified_dir = base_dir / "unified"
        if unified_dir.exists():
            csv_files = list(unified_dir.glob("*.csv"))
            print(f"  ‚îú‚îÄ‚îÄ unified/ ({len(csv_files)} archivos)")
            for csv in csv_files[-3:]:  # Mostrar √∫ltimos 3
                size_kb = csv.stat().st_size / 1024
                print(f"  ‚îÇ   ‚îî‚îÄ‚îÄ {csv.name} ({size_kb:.1f} KB)")
        
        # Duplicates
        duplicates_dir = base_dir / "duplicates"
        if duplicates_dir.exists():
            csv_files = list(duplicates_dir.glob("*.csv"))
            print(f"  ‚îú‚îÄ‚îÄ duplicates/ ({len(csv_files)} archivos)")
            for csv in csv_files[-3:]:  # Mostrar √∫ltimos 3
                size_kb = csv.stat().st_size / 1024
                print(f"  ‚îÇ   ‚îî‚îÄ‚îÄ {csv.name} ({size_kb:.1f} KB)")
        
        # Reports
        reports_dir = base_dir / "reports"
        if reports_dir.exists():
            csv_files = list(reports_dir.glob("*.csv"))
            print(f"  ‚îî‚îÄ‚îÄ reports/ ({len(csv_files)} archivos)")
            for csv in csv_files[-3:]:  # Mostrar √∫ltimos 3
                size_kb = csv.stat().st_size / 1024
                print(f"      ‚îî‚îÄ‚îÄ {csv.name} ({size_kb:.1f} KB)")
    
    def listar_csvs_unificados(self) -> List[Dict[str, Any]]:
        """Listar CSVs unificados disponibles."""
        csvs = get_unified_csv_list()
        return csvs
    
    def seleccionar_csv(self) -> Optional[str]:
        """Permitir al usuario seleccionar un CSV."""
        csvs = self.listar_csvs_unificados()
        
        if not csvs:
            print("\n[ERROR] No se encontraron archivos CSV unificados.")
            print("[INFO] Ejecuta primero el proceso de automatizaci√≥n.")
            input("\nPresiona Enter para continuar...")
            return None
        
        print("\n" + "="*70)
        print("ARCHIVOS CSV UNIFICADOS DISPONIBLES")
        print("="*70)
        
        for i, csv_info in enumerate(csvs, 1):
            from datetime import datetime
            fecha = datetime.fromtimestamp(csv_info['modified']).strftime('%Y-%m-%d %H:%M:%S')
            print(f"\n{i}. {csv_info['filename']}")
            print(f"   Ruta: {csv_info['filepath']}")
            print(f"   Tama√±o: {csv_info['size_kb']:.1f} KB")
            print(f"   Modificado: {fecha}")
        
        try:
            opcion = input(f"\nSelecciona un archivo (1-{len(csvs)}): ").strip()
            idx = int(opcion) - 1
            if 0 <= idx < len(csvs):
                return csvs[idx]['filepath']
            else:
                print("[ERROR] Opci√≥n inv√°lida")
                return None
        except (ValueError, IndexError):
            print("[ERROR] Opci√≥n inv√°lida")
            return None
    
    def seleccionar_articulos(self, csv_path: str) -> List[int]:
        """Permitir al usuario seleccionar art√≠culos del CSV."""
        try:
            df = self.text_extractor.read_unified_csv(csv_path)
            
            print("\n" + "="*70)
            print(f"ART√çCULOS DISPONIBLES ({len(df)} total)")
            print("="*70)
            
            # Mostrar primeros 20 art√≠culos
            mostrar = min(20, len(df))
            for i in range(mostrar):
                titulo = df.iloc[i]['title'][:60] + "..." if len(df.iloc[i]['title']) > 60 else df.iloc[i]['title']
                print(f"{i+1:3d}. {titulo}")
            
            if len(df) > 20:
                print(f"\n... y {len(df) - 20} art√≠culos m√°s")
            
            print("\nSelecciona 2 o m√°s art√≠culos (ej: 1,2,3 o 1-5):")
            seleccion = input("Art√≠culos: ").strip()
            
            indices = self._parse_seleccion(seleccion, len(df))
            
            if len(indices) < 2:
                print("[ERROR] Debes seleccionar al menos 2 art√≠culos")
                return []
            
            print(f"\n[OK] Seleccionados {len(indices)} art√≠culos: {[i+1 for i in indices]}")
            return indices
            
        except Exception as e:
            print(f"[ERROR] Error leyendo CSV: {e}")
            return []
    
    def _parse_seleccion(self, seleccion: str, max_indices: int) -> List[int]:
        """Parsear string de selecci√≥n (ej: "1,2,3" o "1-5")."""
        indices = set()
        
        for part in seleccion.split(','):
            part = part.strip()
            if '-' in part:
                # Rango
                inicio, fin = part.split('-', 1)
                try:
                    inicio_idx = int(inicio.strip()) - 1
                    fin_idx = int(fin.strip()) - 1
                    for i in range(min(inicio_idx, fin_idx), max(inicio_idx, fin_idx) + 1):
                        if 0 <= i < max_indices:
                            indices.add(i)
                except ValueError:
                    pass
            else:
                # √çndice individual
                try:
                    idx = int(part) - 1
                    if 0 <= idx < max_indices:
                        indices.add(idx)
                except ValueError:
                    pass
        
        return sorted(list(indices))
    
    def mostrar_algoritmos_disponibles(self):
        """Mostrar informaci√≥n sobre los algoritmos disponibles."""
        print("\n" + "="*70)
        print("ALGORITMOS DE SIMILITUD TEXTUAL DISPONIBLES")
        print("="*70)
        
        algoritmos = [
            {
                'nombre': '1. Levenshtein (Distancia de Edici√≥n)',
                'tipo': 'Cl√°sico - Distancia de edici√≥n',
                'descripcion': 'Calcula el n√∫mero m√≠nimo de operaciones (inserci√≥n, eliminaci√≥n, sustituci√≥n) necesarias para convertir un texto en otro.'
            },
            {
                'nombre': '2. Damerau-Levenshtein',
                'tipo': 'Cl√°sico - Distancia de edici√≥n',
                'descripcion': 'Similar a Levenshtein pero incluye transposici√≥n de caracteres adyacentes como operaci√≥n adicional.'
            },
            {
                'nombre': '3. Jaccard',
                'tipo': 'Cl√°sico - Vectorizaci√≥n estad√≠stica',
                'descripcion': 'Mide la similitud entre dos conjuntos usando la intersecci√≥n sobre la uni√≥n de n-gramas.'
            },
            {
                'nombre': '4. TF-IDF Cosine Similarity',
                'tipo': 'Cl√°sico - Vectorizaci√≥n estad√≠stica',
                'descripcion': 'Usa Term Frequency-Inverse Document Frequency para vectorizar textos y calcula similitud del coseno.'
            },
            {
                'nombre': '5. Sentence-BERT',
                'tipo': 'IA - Embeddings sem√°nticos',
                'descripcion': 'Usa modelos transformer pre-entrenados para generar embeddings sem√°nticos y calcular similitud.'
            },
            {
                'nombre': '6. LLM-based Similarity',
                'tipo': 'IA - Similitud contextual',
                'descripcion': 'Simula an√°lisis basado en modelos de lenguaje grandes para capturar similitud sem√°ntica profunda.'
            }
        ]
        
        for algo in algoritmos:
            print(f"\n{algo['nombre']}")
            print(f"  Tipo: {algo['tipo']}")
            print(f"  Descripci√≥n: {algo['descripcion']}")
        
        print("\n" + "="*70)
        print("\n[INFO] Todos los algoritmos proporcionan explicaci√≥n detallada paso a paso")
        print("      con detalles matem√°ticos y algor√≠tmicos.")
        input("\nPresiona Enter para continuar...")
    
    def analizar_similitud_articulos(self, csv_path: str, indices: List[int]):
        """Analizar similitud entre art√≠culos seleccionados."""
        try:
            df = self.text_extractor.read_unified_csv(csv_path)
            articles_data = self.text_extractor.extract_abstracts(df, indices)
            
            if len(articles_data) < 2:
                print("[ERROR] Necesitas al menos 2 art√≠culos para comparar")
                return
            
            print("\n" + "="*70)
            print("AN√ÅLISIS DE SIMILITUD TEXTUAL")
            print("="*70)
            
            # Mostrar art√≠culos seleccionados
            print("\nArt√≠culos seleccionados:")
            for art in articles_data:
                print(f"\n  Art√≠culo {art['index']+1}:")
                print(f"    T√≠tulo: {art['title'][:70]}...")
                print(f"    Abstract (primeros 100 chars): {art['abstract'][:100]}...")
            
            # Men√∫ de algoritmos
            print("\n" + "="*70)
            print("Selecciona algoritmo(s) a ejecutar:")
            print("  1. Todos los algoritmos")
            print("  2. Solo algoritmos cl√°sicos (1-4)")
            print("  3. Solo algoritmos de IA (5-6)")
            print("  4. Levenshtein")
            print("  5. Damerau-Levenshtein")
            print("  6. Jaccard")
            print("  7. TF-IDF Cosine")
            print("  8. Sentence-BERT")
            print("  9. LLM-based")
            print("  0. Volver")
            
            opcion = input("\nOpci√≥n: ").strip()
            
            textos = [art['abstract'] for art in articles_data]
            
            if opcion == "1":
                self._ejecutar_todos_algoritmos(textos, articles_data)
            elif opcion == "2":
                self._ejecutar_algoritmos_clasicos(textos, articles_data)
            elif opcion == "3":
                self._ejecutar_algoritmos_ia(textos, articles_data)
            elif opcion == "4":
                self._ejecutar_algoritmo_individual("levenshtein", textos, articles_data)
            elif opcion == "5":
                self._ejecutar_algoritmo_individual("damerau", textos, articles_data)
            elif opcion == "6":
                self._ejecutar_algoritmo_individual("jaccard", textos, articles_data)
            elif opcion == "7":
                self._ejecutar_algoritmo_individual("tfidf", textos, articles_data)
            elif opcion == "8":
                self._ejecutar_algoritmo_individual("sbert", textos, articles_data)
            elif opcion == "9":
                self._ejecutar_algoritmo_individual("llm", textos, articles_data)
            else:
                return
            
            input("\nPresiona Enter para continuar...")
            
        except Exception as e:
            print(f"[ERROR] Error en an√°lisis: {e}")
            import traceback
            traceback.print_exc()
            input("\nPresiona Enter para continuar...")
    
    def _ejecutar_todos_algoritmos(self, textos: List[str], articles_data: List[Dict]):
        """Ejecutar todos los algoritmos."""
        algoritmos = [
            ("Levenshtein", self.similarity_service.levenshtein_similarity),
            ("Damerau-Levenshtein", self.similarity_service.damerau_levenshtein_similarity),
            ("Jaccard", lambda t1, t2: self.similarity_service.jaccard_similarity(t1, t2, n=3)),
            ("TF-IDF Cosine", self.similarity_service.tfidf_cosine_similarity),
            ("Sentence-BERT", self.similarity_service.sentence_bert_similarity),
            ("LLM-based", self.similarity_service.llm_based_similarity),
        ]
        
        for nombre, algoritmo in algoritmos:
            print(f"\n\n{'='*70}")
            print(f"ALGORITMO: {nombre.upper()}")
            print("="*70)
            
            # Comparar cada par
            for i in range(len(textos)):
                for j in range(i + 1, len(textos)):
                    resultado = algoritmo(textos[i], textos[j])
                    self._mostrar_resultado_detallado(resultado, articles_data[i], articles_data[j])
    
    def _ejecutar_algoritmos_clasicos(self, textos: List[str], articles_data: List[Dict]):
        """Ejecutar solo algoritmos cl√°sicos."""
        algoritmos = [
            ("Levenshtein", self.similarity_service.levenshtein_similarity),
            ("Damerau-Levenshtein", self.similarity_service.damerau_levenshtein_similarity),
            ("Jaccard", lambda t1, t2: self.similarity_service.jaccard_similarity(t1, t2, n=3)),
            ("TF-IDF Cosine", self.similarity_service.tfidf_cosine_similarity),
        ]
        
        for nombre, algoritmo in algoritmos:
            print(f"\n\n{'='*70}")
            print(f"ALGORITMO: {nombre.upper()}")
            print("="*70)
            
            for i in range(len(textos)):
                for j in range(i + 1, len(textos)):
                    resultado = algoritmo(textos[i], textos[j])
                    self._mostrar_resultado_detallado(resultado, articles_data[i], articles_data[j])
    
    def _ejecutar_algoritmos_ia(self, textos: List[str], articles_data: List[Dict]):
        """Ejecutar solo algoritmos de IA."""
        algoritmos = [
            ("Sentence-BERT", self.similarity_service.sentence_bert_similarity),
            ("LLM-based", self.similarity_service.llm_based_similarity),
        ]
        
        for nombre, algoritmo in algoritmos:
            print(f"\n\n{'='*70}")
            print(f"ALGORITMO: {nombre.upper()}")
            print("="*70)
            
            for i in range(len(textos)):
                for j in range(i + 1, len(textos)):
                    resultado = algoritmo(textos[i], textos[j])
                    self._mostrar_resultado_detallado(resultado, articles_data[i], articles_data[j])
    
    def _ejecutar_algoritmo_individual(self, tipo: str, textos: List[str], articles_data: List[Dict]):
        """Ejecutar un algoritmo individual."""
        algoritmos_map = {
            "levenshtein": ("Levenshtein", self.similarity_service.levenshtein_similarity),
            "damerau": ("Damerau-Levenshtein", self.similarity_service.damerau_levenshtein_similarity),
            "jaccard": ("Jaccard", lambda t1, t2: self.similarity_service.jaccard_similarity(t1, t2, n=3)),
            "tfidf": ("TF-IDF Cosine", self.similarity_service.tfidf_cosine_similarity),
            "sbert": ("Sentence-BERT", self.similarity_service.sentence_bert_similarity),
            "llm": ("LLM-based", self.similarity_service.llm_based_similarity),
        }
        
        if tipo not in algoritmos_map:
            print(f"[ERROR] Algoritmo desconocido: {tipo}")
            return
        
        nombre, algoritmo = algoritmos_map[tipo]
        
        print(f"\n\n{'='*70}")
        print(f"ALGORITMO: {nombre.upper()}")
        print("="*70)
        
        for i in range(len(textos)):
            for j in range(i + 1, len(textos)):
                resultado = algoritmo(textos[i], textos[j])
                self._mostrar_resultado_detallado(resultado, articles_data[i], articles_data[j])
    
    def _mostrar_resultado_detallado(self, resultado, art1: Dict, art2: Dict):
        """Mostrar resultado detallado de un algoritmo."""
        print(f"\n{'-'*70}")
        print(f"Comparaci√≥n: Art√≠culo {art1['index']+1} vs Art√≠culo {art2['index']+1}")
        print(f"{'-'*70}")
        print(f"\nüìä Score de Similitud: {resultado.similarity_score:.4f}")
        print(f"‚è±Ô∏è  Tiempo de procesamiento: {resultado.processing_time:.4f} segundos")
        
        print(f"\nüìù Explicaci√≥n Detallada:")
        print(f"{'='*70}")
        print(resultado.explanation)
        
        print(f"\nüîç Detalles Adicionales:")
        print(f"{'='*70}")
        for key, value in resultado.details.items():
            if value is not None:
                if isinstance(value, list) and len(value) > 10:
                    print(f"  {key}: [Lista con {len(value)} elementos - mostrando primeros 10]")
                    print(f"    {value[:10]}")
                elif isinstance(value, dict):
                    print(f"  {key}:")
                    for k, v in list(value.items())[:5]:  # Mostrar primeros 5
                        print(f"    {k}: {v}")
                else:
                    print(f"  {key}: {value}")
        
        print(f"\n{'-'*70}\n")
    
    def ejecutar_analisis_frecuencia(self):
        """Ejecutar an√°lisis de frecuencia de palabras (Requerimiento 3)."""
        print("\n" + "="*70)
        print("AN√ÅLISIS DE FRECUENCIA DE PALABRAS - REQUERIMIENTO 3")
        print("="*70)
        
        # Seleccionar CSV
        csv_path = self.seleccionar_csv()
        if not csv_path:
            input("\nPresiona Enter para continuar...")
            return
        
        print("\n[INFO] Analizando frecuencia de palabras...")
        print("[INFO] Esto puede tardar unos momentos...")
        
        try:
            # Solicitar par√°metros
            category = input("\nCategor√≠a de an√°lisis [Generative AI in Education]: ").strip()
            if not category:
                category = "Generative AI in Education"
            
            try:
                max_words = input("M√°ximo de palabras asociadas [15]: ").strip()
                max_words = int(max_words) if max_words else 15
            except ValueError:
                max_words = 15
            
            # Ejecutar an√°lisis
            resultado = self.word_frequency_service.analyze_word_frequency(
                csv_path=csv_path,
                category=category,
                max_associated_words=max_words
            )
            
            # Mostrar resultados
            print("\n" + "="*70)
            print("RESULTADOS DEL AN√ÅLISIS DE FRECUENCIA")
            print("="*70)
            print(f"\nüìä Categor√≠a: {resultado.category}")
            print(f"üìÑ Total de art√≠culos analizados: {resultado.total_articles}")
            print(f"üìù Total de palabras analizadas: {resultado.total_words_analyzed}")
            
            print(f"\nüî§ Palabras de la categor√≠a ({len(resultado.category_words)}):")
            print("-" * 70)
            for word in sorted(resultado.category_words):
                freq = resultado.category_frequencies.get(word, 0)
                print(f"  ‚Ä¢ {word}: {freq} apariciones")
            
            print(f"\nüîó Palabras asociadas (Top {len(resultado.associated_words)}):")
            print("-" * 70)
            for word, freq, precision in resultado.associated_words:
                print(f"  ‚Ä¢ {word}: {freq} apariciones (precisi√≥n: {precision:.2%})")
            
            # Obtener top palabras de abstracts
            print(f"\nüìà Top palabras en abstracts:")
            print("-" * 70)
            top_abstracts = self.word_frequency_service.get_top_words_from_fields(
                field="abstract",
                top_n=15,
                csv_path=csv_path
            )
            for word, count in top_abstracts:
                print(f"  ‚Ä¢ {word}: {count} apariciones")
            
            print("\n" + "="*70)
            print("[OK] An√°lisis completado exitosamente")
            print("="*70)
            
        except Exception as e:
            print(f"\n[ERROR] Error durante el an√°lisis: {e}")
            import traceback
            traceback.print_exc()
        
        input("\nPresiona Enter para continuar...")
    
    def ejecutar_agrupamiento_jerarquico(self):
        """Ejecutar agrupamiento jer√°rquico (Requerimiento 4)."""
        print("\n" + "="*70)
        print("AGRUPAMIENTO JER√ÅRQUICO DE ABSTRACTS - REQUERIMIENTO 4")
        print("="*70)
        
        # Seleccionar CSV
        csv_path = self.seleccionar_csv()
        if not csv_path:
            input("\nPresiona Enter para continuar...")
            return
        
        print("\n[INFO] Configurando par√°metros de clustering...")
        
        try:
            # Solicitar par√°metros
            try:
                limit = input("L√≠mite de documentos [None = todos]: ").strip()
                limit = int(limit) if limit else None
            except ValueError:
                limit = None
            
            try:
                max_features = input("M√°ximo de caracter√≠sticas TF-IDF [1500]: ").strip()
                max_features = int(max_features) if max_features else 1500
            except ValueError:
                max_features = 1500
            
            methods_input = input("M√©todos de linkage [single,complete,average]: ").strip()
            if methods_input:
                methods = [m.strip() for m in methods_input.split(",")]
            else:
                methods = ["single", "complete", "average"]
            
            try:
                distance_threshold = input("Umbral de distancia [1.0]: ").strip()
                distance_threshold = float(distance_threshold) if distance_threshold else 1.0
            except ValueError:
                distance_threshold = 1.0
            
            print("\n[INFO] Ejecutando agrupamiento jer√°rquico...")
            print("[INFO] Esto puede tardar varios minutos dependiendo del tama√±o del dataset...")
            
            # Ejecutar clustering
            resultados = self.clustering_service.perform_hierarchical_clustering(
                csv_path=csv_path,
                limit=limit,
                max_features=max_features,
                methods=methods,
                distance_threshold=distance_threshold
            )
            
            # Mostrar resultados
            print("\n" + "="*70)
            print("RESULTADOS DEL AGRUPAMIENTO JER√ÅRQUICO")
            print("="*70)
            
            best_method = None
            best_correlation = float("-inf")
            
            for method, resultado in resultados.items():
                print(f"\nüìä M√©todo: {method.upper()} (m√©trica: {resultado.metric})")
                print("-" * 70)
                print(f"  ‚Ä¢ Dendrograma: {resultado.dendrogram_path}")
                print(f"  ‚Ä¢ N√∫mero de clusters: {resultado.cluster_count}")
                print(f"  ‚Ä¢ Correlaci√≥n cophen√©tica: {resultado.cophenetic_correlation:.4f}")
                
                if resultado.cophenetic_correlation > best_correlation:
                    best_correlation = resultado.cophenetic_correlation
                    best_method = method
            
            if best_method:
                print(f"\nüèÜ Mejor m√©todo: {best_method.upper()} (correlaci√≥n: {best_correlation:.4f})")
                print(f"   Dendrograma: {resultados[best_method].dendrogram_path}")
            
            print("\n" + "="*70)
            print("[OK] Agrupamiento completado exitosamente")
            print("="*70)
            
        except Exception as e:
            print(f"\n[ERROR] Error durante el agrupamiento: {e}")
            import traceback
            traceback.print_exc()
        
        input("\nPresiona Enter para continuar...")
    
    def ejecutar_analisis_visual(self):
        """Ejecutar an√°lisis visual completo (Requerimiento 5)."""
        print("\n" + "="*70)
        print("AN√ÅLISIS VISUAL - REQUERIMIENTO 5")
        print("="*70)
        
        # Seleccionar CSV
        csv_path = self.seleccionar_csv()
        if not csv_path:
            input("\nPresiona Enter para continuar...")
            return
        
        print("\n[INFO] Configurando an√°lisis visual...")
        
        try:
            # Solicitar par√°metros
            try:
                limit = input("L√≠mite de art√≠culos [None = todos]: ").strip()
                limit = int(limit) if limit else None
            except ValueError:
                limit = None
            
            export_pdf_input = input("Exportar a PDF [S/n]: ").strip().lower()
            export_pdf = export_pdf_input != 'n'
            
            print("\n[INFO] Generando visualizaciones...")
            print("[INFO] Esto incluye:")
            print("  ‚Ä¢ Mapa de calor geogr√°fico")
            print("  ‚Ä¢ Nubes de palabras (abstracts, keywords, combinada)")
            print("  ‚Ä¢ L√≠nea temporal de publicaciones")
            if export_pdf:
                print("  ‚Ä¢ Exportaci√≥n a PDF")
            print("\n[INFO] Esto puede tardar varios minutos...")
            
            # Suprimir logs JSON durante la ejecuci√≥n
            import logging
            import structlog
            original_level = logging.getLogger().level
            logging.getLogger().setLevel(logging.WARNING)
            
            try:
                # Ejecutar visualizaciones
                resultado = self.visualization_service.generate_all_visualizations(
                    csv_path=csv_path,
                    limit=limit,
                    export_pdf=export_pdf
                )
            finally:
                # Restaurar nivel de logging
                logging.getLogger().setLevel(original_level)
            
            # Mostrar resultados
            print("\n" + "="*70)
            print("RESULTADOS DEL AN√ÅLISIS VISUAL")
            print("="*70)
            print(f"\nüó∫Ô∏è  Mapa de calor geogr√°fico:")
            print(f"   {resultado.heatmap_path}")
            
            print(f"\n‚òÅÔ∏è  Nubes de palabras:")
            for field, path in resultado.wordcloud_paths.items():
                print(f"   ‚Ä¢ {field}: {path}")
            
            print(f"\nüìà L√≠nea temporal:")
            print(f"   {resultado.timeline_path}")
            
            if resultado.pdf_path:
                print(f"\nüìÑ Reporte PDF combinado:")
                print(f"   {resultado.pdf_path}")
            
            print("\n" + "="*70)
            print("[OK] An√°lisis visual completado exitosamente")
            print("="*70)
            
        except Exception as e:
            print(f"\n[ERROR] Error durante el an√°lisis visual: {e}")
            import traceback
            traceback.print_exc()
        
        input("\nPresiona Enter para continuar...")
    
    def ejecutar(self):
        """Ejecutar el men√∫ principal."""
        csv_seleccionado = None
        
        while True:
            self.limpiar_pantalla()
            self.mostrar_banner()
            self.mostrar_menu_principal()
            
            opcion = input("\nSelecciona una opci√≥n: ").strip()
            
            if opcion == "1":
                # Submen√∫ de scraping
                while True:
                    self.limpiar_pantalla()
                    self.mostrar_submenu_scraping()
                    sub_opcion = input("\nOpci√≥n: ").strip()
                    
                    if sub_opcion == "1":
                        self.ejecutar_proceso_automatizacion()
                        csv_seleccionado = None  # Resetear selecci√≥n
                    elif sub_opcion == "2":
                        self.mostrar_estructura_resultados()
                        input("\nPresiona Enter para continuar...")
                    elif sub_opcion == "3":
                        break
                    else:
                        print("[ERROR] Opci√≥n inv√°lida")
            
            elif opcion == "2":
                # Submen√∫ de similitud
                while True:
                    self.limpiar_pantalla()
                    self.mostrar_submenu_similitud()
                    
                    if csv_seleccionado:
                        print(f"\n[INFO] CSV seleccionado: {Path(csv_seleccionado).name}")
                    
                    sub_opcion = input("\nOpci√≥n: ").strip()
                    
                    if sub_opcion == "1":
                        csv_seleccionado = self.seleccionar_csv()
                    elif sub_opcion == "2":
                        if not csv_seleccionado:
                            csv_seleccionado = self.seleccionar_csv()
                        if csv_seleccionado:
                            indices = self.seleccionar_articulos(csv_seleccionado)
                            if indices:
                                self.analizar_similitud_articulos(csv_seleccionado, indices)
                    elif sub_opcion == "3":
                        self.mostrar_algoritmos_disponibles()
                    elif sub_opcion == "4":
                        break
                    else:
                        print("[ERROR] Opci√≥n inv√°lida")
            
            elif opcion == "3":
                # An√°lisis de frecuencia de palabras
                self.ejecutar_analisis_frecuencia()
            
            elif opcion == "4":
                # Agrupamiento jer√°rquico
                self.ejecutar_agrupamiento_jerarquico()
            
            elif opcion == "5":
                # An√°lisis visual
                self.ejecutar_analisis_visual()
            
            elif opcion == "6":
                print("\n[INFO] Saliendo...")
                break
            else:
                print("[ERROR] Opci√≥n inv√°lida")
                input("\nPresiona Enter para continuar...")


def main():
    """Funci√≥n principal."""
    try:
        menu = MenuPrincipal()
        menu.ejecutar()
    except KeyboardInterrupt:
        print("\n\n[INFO] Programa interrumpido por el usuario")
    except Exception as e:
        print(f"\n[ERROR] Error fatal: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

